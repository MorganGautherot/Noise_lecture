{"cells":[{"cell_type":"markdown","metadata":{"id":"pyyufcYvd84S"},"source":["# Prétraitement des données audio"]},{"cell_type":"markdown","metadata":{"id":"mNjCaJY7gC1Z"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v71WgwXDd5v3"},"outputs":[],"source":["import librosa, librosa.display\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import os\n","import json\n","from sklearn.model_selection import train_test_split\n","import tensorflow.keras as keras"]},{"cell_type":"markdown","metadata":{"id":"rPsDRfOLiJQ0"},"source":["# Connection avec Google Drive"]},{"cell_type":"markdown","metadata":{"id":"0gyxdRT-iSbz"},"source":["Ajoutez un raccourci de ce dossier à votre Google Drive :\n","\n","https://drive.google.com/drive/folders/1NGH6ntk3qH8Odo7q8YxDS0iqV-httZUR?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnrxxvGsiSAv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"73XQlr_1_2y0"},"source":["# Découverte de la librairie Librosa"]},{"cell_type":"markdown","metadata":{"id":"Lq5PNaPb_2y0"},"source":["Librosa est une bibliothèque qui facilite la manipulation des données audio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPfxOjwjieEJ"},"outputs":[],"source":["file = \"drive/MyDrive/Music_genre_classification/genres_original/pop/pop.00008.wav\""]},{"cell_type":"markdown","metadata":{"id":"WSMfUH2b_2y0"},"source":["# Importer une musique"]},{"cell_type":"markdown","metadata":{"id":"SMfB9b62_2y1"},"source":["Le paramètre `sr` correspond à la fréquence d'échantillonnage, et nous utiliserons 22050 par défaut tout au long de ce TP.\n","\n","Utilisez la fonction load de la bibliothèque `Librosa` pour importer le fichier `file`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lm8Wqk1ai6F4"},"outputs":[],"source":["signal, sr = None"]},{"cell_type":"markdown","metadata":{"id":"mV0zWtK__2y1"},"source":["# Visualisation de l'onde"]},{"cell_type":"markdown","metadata":{"id":"dktC1MNs_2y1"},"source":["Utilisez la fonction `waveshow` de Librosa pour visualiser le signal de l'onde.\n","\n","Ensuite, servez-vous des fonctions `xlabel` et `ylabel` pour indiquer où se trouvent le temps et l'amplitude sur le graphique."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E60MC3UIi8hM"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["# La transformée de fourier"],"metadata":{"id":"uhFQbYHMDLrD"}},{"cell_type":"markdown","metadata":{"id":"R4AniA9r_2y1"},"source":["Appliquez une transformée de Fourier au signal en utilisant la fonction `fft` de Numpy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIOv6rkDjaXJ"},"outputs":[],"source":["fft = None"]},{"cell_type":"markdown","metadata":{"id":"BYGUmRBr_2y1"},"source":["Utilisez la valeur absolue de la transformée de Fourier pour obtenir la magnitude de l'onde, en vous servant de la fonction `abs` de Numpy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPvvG-MjkXMa"},"outputs":[],"source":["magnitude = None"]},{"cell_type":"markdown","metadata":{"id":"Wyfd40vN_2y1"},"source":["Utilisez la fonction `linspace` de Numpy pour structurer les fréquences de l'onde."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9hzJj2YkhVV"},"outputs":[],"source":["frequency = None"]},{"cell_type":"markdown","metadata":{"id":"OvAyViwE_2y1"},"source":["Visualisation de l'onde dans le domaine fréquence-magnitude.\n","\n","Utilisez la fonction `plot` de Matplotlib pour tracer le graphique de la magnitude en fonction de la fréquence.\n","\n","Servez-vous de `xlabel` et `ylabel` pour nommer les axes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNiOfNkXktPY"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["# Passage au spectrogramme"],"metadata":{"id":"VpgRkebVDwNp"}},{"cell_type":"markdown","metadata":{"id":"9z2XjjYx_2y1"},"source":["Utilisez le spectrogramme pour réintégrer la composante temporelle dans la représentation de l'onde."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oh1gCtWvljvr"},"outputs":[],"source":[" # Number of time for each sample\n","n_fft=2048\n","\n","# the amount we slide to the right at each time\n","hop_length = 512"]},{"cell_type":"markdown","metadata":{"id":"P5fexVaK_2y2"},"source":["Appliquez la fonction `core.stft` de Librosa sur le signal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxZdlAQxlbDN"},"outputs":[],"source":["stft = None"]},{"cell_type":"markdown","metadata":{"id":"fRKLA5_s_2y2"},"source":["Appliquez la valeur absolue du résultat pour obtenir le spectrogramme, en utilisant la fonction `abs` de Numpy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZ35cuPjl6K5"},"outputs":[],"source":["spectogram = None"]},{"cell_type":"markdown","metadata":{"id":"TxP4w_Xb_2y2"},"source":["Visualisez le spectrogramme à l'aide de la fonction `specshow` de Librosa.\n","\n","N'oubliez pas d'utiliser `xlabel` et `ylabel` pour nommer les axes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"duO1rS4Xl-vG"},"outputs":[],"source":["None"]},{"cell_type":"markdown","metadata":{"id":"1AtnQKpB_2y2"},"source":["On ne distingue pas grand-chose.\n","\n","Appliquez un logarithme aux données du spectrogramme pour obtenir le résultat en décibels, en utilisant la fonction `amplitude_to_db` de Librosa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6KBpmaE_2y2"},"outputs":[],"source":["log_spectogram = None"]},{"cell_type":"markdown","metadata":{"id":"d1GGSblH_2y2"},"source":["Visualisez le résultat, qui devrait être plus facile à lire, en utilisant la fonction `specshow`.\n","\n","N'oubliez pas d'ajouter les axes avec `xlabel` et `ylabel`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sU9ll5NmBww"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["# Le mel frequency cepstral coefficients"],"metadata":{"id":"p3VzW7gjEp5e"}},{"cell_type":"markdown","metadata":{"id":"N0DHFc7B_2y2"},"source":["Nous pouvons représenter les données audio d'une autre manière en utilisant les MFCCs."]},{"cell_type":"markdown","metadata":{"id":"1OVM6ApD_2y2"},"source":["Utilisez la fonction `mfcc` de Librosa pour l'appliquer à notre signal.\n","\n","Fixez le nombre de composantes `n_mfcc` à 13."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iiJdZvvmhaP"},"outputs":[],"source":["MFFCs = None"]},{"cell_type":"markdown","metadata":{"id":"xl0INCKh_2y2"},"source":["Visualisez le résultat en utilisant la fonction `specshow` de Librosa.\n","\n","N'oubliez pas d'ajouter les axes avec `ylabel` et `xlabel`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyAs8jBgm8CG"},"outputs":[],"source":["None"]},{"cell_type":"markdown","metadata":{"id":"l-DIcITjL5O8"},"source":["# Création du jeu de données"]},{"cell_type":"markdown","metadata":{"id":"vjAeqKsi_2y6"},"source":["Il est maintenant temps de transformer l'ensemble de notre jeu de données en appliquant la transformation MFCC sur nos pistes, afin d'obtenir des données exploitables pour le deep learning."]},{"cell_type":"markdown","metadata":{"id":"QoXxbEye_2y6"},"source":["Identification des variables globales"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnNKikZ5P6U9"},"outputs":[],"source":["# sample rate\n","SAMPLE_RATE = 22050\n","\n","# Longueur de chaque morceau du jeu de données\n","DURATION = 30\n","\n","# durée de chaque segment de chanson\n","SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"]},{"cell_type":"markdown","metadata":{"id":"CmPUe0wz_2y6"},"source":["Votre objectif est de créer une fonction qui prendra un `signal` et le découpera en plusieurs segments pour augmenter artificiellement le nombre d'exemples dans le jeu de données d'entraînement."]},{"cell_type":"markdown","metadata":{"id":"X_o780n6MPlE"},"source":["`num_segments` divise chaque piste en plusieurs segments musicaux.\n","\n","`num_samples_per_segment` représente le nombre d'échantillons découpés par segment.\n","\n","`expected_num_mfcc_vectors_per_segment` correspond au nombre de vecteurs par segment. Il est essentiel d'avoir le même nombre de vecteurs pour chaque segment ; sinon, l'observation ne sera pas sauvegardée.\n","\n","`data` est le dictionnaire où vous allez stocker vos données. Il contient une clé `mfcc` pour les données MFCC des signaux et une clé `labels` pour le genre de musique associé.\n","\n","`file_path` désigne le chemin vers le fichier à traiter.\n","\n","`signal` est le signal à analyser.\n","\n","`label` représente le genre de musique auquel appartient le signal.\n","\n","`sample_rate` est la fréquence d'échantillonnage, par défaut fixée à 22050.\n","\n","`n_fft` correspond à la durée de chaque échantillon, par défaut 2048.\n","\n","`hop_length` indique le déplacement de la fenêtre entre chaque échantillon, avec pour objectif de créer un recouvrement.\n","\n","`n_mfcc` est le nombre de composantes que l'on souhaite extraire du signal, par défaut 13."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj2btTxO_2y6"},"outputs":[],"source":["def process_segments_from_musics(num_segments:int,\n","                                 num_samples_per_segment:int,\n","                                 expected_num_mfcc_vectors_per_segment:int,\n","                                 data:dict,\n","                                 file_path:str,\n","                                 signal:np.ndarray,\n","                                 label:int,\n","                                 sample_rate:int=22050,\n","                                 n_fft:int=2048,\n","                                 hop_length:int=512,\n","                                 n_mfcc:int=13)->dict:\n","\n","  # process segments extracting mfcc and storing data\n","  for s in range(num_segments):\n","    start_sample = None\n","    finish_sample = None\n","    mfcc = None\n","\n","    mfcc = mfcc.T\n","\n","    # store mfcc for segment if it has the expected length\n","    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n","      data[\"mfcc\"].append(mfcc.tolist())\n","      data[\"labels\"].append(label-1)\n","      print(\"{}, segment:{}\".format(file_path, s))\n","\n","  return data"]},{"cell_type":"markdown","metadata":{"id":"7jBf9-Jx_2y6"},"source":["`num_segments` permet de diviser chaque piste en plusieurs segments musicaux.\n","\n","`num_samples_per_segment` indique le nombre d'échantillons à découper par segment.\n","\n","`expected_num_mfcc_vectors_per_segment` représente le nombre de vecteurs par segment. Il est nécessaire d'avoir le même nombre de vecteurs pour chaque segment ; sinon, l'observation ne sera pas sauvegardée.\n","\n","`data` est le dictionnaire où vous allez stocker vos données. Il contient une clé `mfcc` pour les données MFCC des signaux et une clé `labels` pour le genre de musique associé.\n","\n","`file_path` désigne le chemin vers le fichier à traiter.\n","\n","`dirpath` est le chemin vers le dossier à traiter.\n","\n","`sample_rate` correspond à la fréquence d'échantillonnage, par défaut fixée à 22050.\n","\n","`n_fft` indique la durée de chaque échantillon, par défaut 2048.\n","\n","`hop_length` représente le déplacement de la fenêtre entre chaque échantillon, avec pour objectif de créer un recouvrement.\n","\n","`n_mfcc` est le nombre de composantes que l'on souhaite extraire du signal, par défaut 13."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6Q9T0bF_2y6"},"outputs":[],"source":["def process_musics(num_segments:int,\n","                   num_samples_per_segment:int,\n","                   expected_num_mfcc_vectors_per_segment:int,\n","                   data:dict,\n","                   filenames:str,\n","                   dirpath:str,\n","                   label:int,\n","                   sample_rate:int=22050,\n","                   n_fft:int=2048,\n","                   hop_length:int=512,\n","                   n_mfcc:int=13)->dict:\n","  # process files for a specific genre\n","  for f in filenames:\n","    # load the audio file\n","    file_path = os.path.join(dirpath, f)\n","    signal, _ = None\n","\n","    data = None\n","\n","  return data"]},{"cell_type":"markdown","metadata":{"id":"bQSQhnlE_2y6"},"source":["`num_segments` permet de diviser chaque piste en plusieurs segments musicaux.\n","\n","`num_samples_per_segment` indique le nombre d'échantillons à découper par segment.\n","\n","`expected_num_mfcc_vectors_per_segment` représente le nombre de vecteurs par segment. Il est essentiel d'avoir le même nombre de vecteurs pour chaque segment ; sinon, l'observation ne sera pas sauvegardée.\n","\n","`data` est le dictionnaire où vous allez stocker vos données. Il contient une clé `mfcc` pour les données MFCC des signaux et une clé `labels` pour le genre de musique associé. Une clé `mapping` contiendra un vecteur avec les différents genres écrits, associés au label par leur indice.\n","\n","`dataset_path` désigne le chemin vers les dossiers de genres musicaux à traiter.\n","\n","`sample_rate correspond` à la fréquence d'échantillonnage, par défaut fixée à 22050.\n","\n","`n_fft` indique la durée de chaque échantillon, par défaut 2048.\n","\n","`hop_length` représente le déplacement de la fenêtre entre chaque échantillon, avec pour objectif de créer un recouvrement.\n","\n","`n_mfcc` est le nombre de composantes que l'on souhaite extraire du signal, par défaut 13."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkDElemb_2y6"},"outputs":[],"source":["def process_musics_gender(num_segments:int,\n","                          num_samples_per_segment:int,\n","                          expected_num_mfcc_vectors_per_segment:int,\n","                          data:dict,\n","                          dataset_path:str,\n","                          sample_rate:int=22050,\n","                          n_fft:int=2048,\n","                          hop_length:int=512,\n","                          n_mfcc:int=13)->dict:\n","  # Loop through all the genres\n","  for label, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n","    # ensure that we're not at the root level\n","    if dirpath is not dataset_path:\n","      # save the semantic label\n","      dirpath_components = dirpath.split(\"/\")\n","      semantic_label = dirpath_components[-1]\n","      data[\"mapping\"].append(semantic_label)\n","      print('\\nProcessing {}'.format(semantic_label))\n","      data = None\n","  return data\n"]},{"cell_type":"markdown","metadata":{"id":"UwEyeq6m_2y7"},"source":["`dataset_path` désigne le chemin vers les dossiers contenant les genres musicaux à traiter.\n","\n","`json_path` est le chemin où sera sauvegardé le fichier JSON contenant toutes les données traitées.\n","\n","`sample_rate` correspond à la fréquence d'échantillonnage, par défaut fixée à 22050.\n","\n","`n_fft` indique la durée de chaque échantillon, par défaut 2048.\n","\n","`hop_length` représente le déplacement de la fenêtre entre chaque échantillon, avec pour objectif de créer un recouvrement.\n","\n","`n_mfcc` est le nombre de composantes que l'on souhaite extraire du signal, par défaut 13.\n","\n","`num_segments` permet de diviser chaque piste en plusieurs segments musicaux"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"am_NxH4W_2y7"},"outputs":[],"source":["def save_mfcc(dataset_path:str,\n","              json_path:str,\n","              sample_rate:int=22050,\n","              n_fft:int=2048,\n","              hop_length:int=512,\n","              n_mfcc:int=13,\n","              num_segments:int=5)->None:\n","  # dictionary to store data\n","  data = {\n","      \"mapping\": [],\n","      \"labels\": [],\n","      \"mfcc\": []\n","  }\n","\n","  num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n","  expected_num_mfcc_vectors_per_segment = np.ceil(num_samples_per_segment / hop_length)\n","\n","  data = None\n","\n","  with open(json_path, \"w\") as fp:\n","    json.dump(data, fp, indent=4)\n"]},{"cell_type":"markdown","source":["Applliquez les fonction sur le jeu de données"],"metadata":{"id":"vyIIFjxxHeTv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibmqCarJ_2y7"},"outputs":[],"source":["None"]},{"cell_type":"markdown","metadata":{"id":"GqGiZr0Is0PN"},"source":["# Entraînement du modèle"]},{"cell_type":"markdown","metadata":{"id":"969gIBql_2y7"},"source":["## Création du générateur"]},{"cell_type":"markdown","metadata":{"id":"8-XndVCD_2y7"},"source":["Créez une fonction génératrice qui va lire votre fichier JSON et séparer les entrées, qui sont les MFCC extraits, des cibles, qui correspondent aux genres de musique associés."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_uZwypEksIT"},"outputs":[],"source":["def load_data(dataset_path:str):\n","  with open(dataset_path, \"r\") as fp:\n","    data = json.load(fp)\n","\n","    # Convert lists into numpy arrays\n","    inputs = None\n","    targets = None\n","\n","    return inputs, targets"]},{"cell_type":"markdown","metadata":{"id":"zIiNQdbg_2y8"},"source":["Chargez le jeu de données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuRCl0Xp_2y8"},"outputs":[],"source":["inputs, targets = None"]},{"cell_type":"markdown","metadata":{"id":"GDqU5j6f_2y8"},"source":["## Séparation du jeu de données d'entraînement et de test"]},{"cell_type":"markdown","metadata":{"id":"hlipEmia_2y8"},"source":["Utilisez la fonction `train_test_split` de Scikit-learn pour diviser le jeu de données en deux parties.\n","\n","Appliquez un coefficient de 30 % pour le jeu de test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfytqZJQ_2y8"},"outputs":[],"source":["inputs_train, inputs_test, targets_train, targets_test = None"]},{"cell_type":"markdown","metadata":{"id":"dsGFnXwl_2y8"},"source":["## Initialisation du modèle"]},{"cell_type":"markdown","metadata":{"id":"WZLebfKk_2y8"},"source":["Vous allez créer une fonction `build_model` qui prend en entrée la dimension d'entrée du modèle, `inputs_shape`, et qui va construire l'architecture suivante à l'aide de la fonction `Sequential` :\n","\n","- Une couche de `Flatten` pour transformer vos spectrogrammes en vecteurs.\n","- Une couche de neurones entièrement connectés, utilisant la fonction `Dense`, avec 512 neurones et la fonction d'activation ReLU.\n","- Une autre couche de neurones entièrement connectés, avec 256 neurones et la fonction d'activation ReLU.\n","- Une couche supplémentaire de neurones entièrement connectés, avec 64 neurones et la fonction d'activation ReLU.\n","- Enfin, une couche de sortie de neurones entièrement connectés, avec 10 neurones et la fonction d'activation softmax."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQvjaK54_2y8"},"outputs":[],"source":["def build_model(inputs_shape:tuple):\n","    # build the network architecture\n","    model = keras.Sequential([\n","\n","        # input layer\n","        None\n","\n","        # 1st hidden layer\n","        None\n","\n","        # 2nd hidden layer\n","        None\n","\n","        # 3rd hidden layer\n","        None\n","\n","        # output layer\n","        None\n","    ])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"tyDW5Ilj_2y8"},"source":["Utilisez la fonction que vous avez écrite précédemment pour initialiser votre modèle."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUNimJXB_2y8"},"outputs":[],"source":["model = None"]},{"cell_type":"markdown","metadata":{"id":"Rp9qbcVG_2y8"},"source":["## Choisir l'algorithme d'optimisation"]},{"cell_type":"markdown","metadata":{"id":"ZwZXJn6D_2y8"},"source":["Utilisez l'algorithme d'optimisation `Adam` avec un learning rate de 0.0001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJ_jajDa_2y8"},"outputs":[],"source":["optimizer = None"]},{"cell_type":"markdown","metadata":{"id":"SAlLR4vu_2y8"},"source":["## Compilation du modèle"]},{"cell_type":"markdown","metadata":{"id":"KlH23byY_2y8"},"source":["Utilisez la méthode `compile`pour compiler le modèle avec pour fonction de coût `sparse_categorical_crossentropy` et comme mètrique `accuracy`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csOEA5tm_2y8"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["## Visualisation du modèle"],"metadata":{"id":"YnWaUW1KI4Ab"}},{"cell_type":"markdown","metadata":{"id":"esmpByFh_2y8"},"source":["Visualisez du modèle grâce à la méthode `summary`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"70vAZlhZtmQq"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["## Entraînement du modèle"],"metadata":{"id":"c9K2Qz9UI6Gg"}},{"cell_type":"markdown","metadata":{"id":"uwD1u6mt_2y9"},"source":["Entraînez le modèle en utilisant la méthode `fit`. Spécifiez un jeu de données de validation dans validation_data, un nombre d'époques (`epochs`) de 50, et une taille du batch (`batch_size`) de 32."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ognYlBvtqA2"},"outputs":[],"source":["# train network\n","history = None"]},{"cell_type":"code","source":["def plot_history(history):\n","    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n","\n","        :param history: Training history of model\n","        :return:\n","    \"\"\"\n","\n","    fig, axs = plt.subplots(2)\n","\n","    # create accuracy sublpot\n","    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n","    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n","    axs[0].set_ylabel(\"Accuracy\")\n","    axs[0].legend(loc=\"lower right\")\n","    axs[0].set_title(\"Accuracy eval\")\n","\n","    # create error sublpot\n","    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n","    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n","    axs[1].set_ylabel(\"Error\")\n","    axs[1].set_xlabel(\"Epoch\")\n","    axs[1].legend(loc=\"upper right\")\n","    axs[1].set_title(\"Error eval\")\n","\n","    plt.show()"],"metadata":{"id":"qAjGA7ZRbpJM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la méthode `evaluate` pour obtenir les performances du modèle sur le jeu de test."],"metadata":{"id":"H5N-VJreZyW5"}},{"cell_type":"code","source":["# plot accuracy/error for training and validation\n","plot_history(history)\n","\n","# evaluate model on test set\n","test_loss, test_acc = None\n","print('\\nTest accuracy:', test_acc)"],"metadata":{"id":"fV0ahiDvbvC-"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}